{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1246818a-972f-498b-84f8-d3bdc61c2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pe import PositionalEncoding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16f22a4-1ccf-4f27-b8ec-0dea5afa6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example config\n",
    "config = {\n",
    "    'model': {\n",
    "        'pe_dim': 10,  # Example value for pe_dim, replace with your actual value\n",
    "        'omega': 1.0,  # Example omega value, replace with your actual value\n",
    "        'sigma': 1.0,  # Example sigma value, replace with your actual value\n",
    "        'pe_bias': True,  # Example bias setting, replace with your actual value\n",
    "        'seed': 42  # Example seed value, replace with your actual value\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfdb79a-1939-479b-b1f4-08e5b534bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract positional encoding arguments from config\n",
    "pe_args = (\n",
    "    1,  # Dimension of the input (wavelengths)\n",
    "    config['model']['pe_dim'],\n",
    "    config['model']['omega'],\n",
    "    config['model']['sigma'],\n",
    "    config['model']['pe_bias'],\n",
    "    config['model']['seed']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148abb9c-86d6-4d9d-a433-b5fa185047e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavelength_grid():\n",
    "    grid = [\n",
    "        (15050, 15850, 0.2),\n",
    "        (15870, 16440, 0.2),\n",
    "        (16475, 17005, 0.2),\n",
    "        (4700, 4930, 0.05),\n",
    "        (5650, 5880, 0.05),\n",
    "        (6420, 6800, 0.05),\n",
    "        (7500, 7920, 0.05)\n",
    "    ]\n",
    "\n",
    "    wavelength_grid = []\n",
    "    for start, end, step in grid:\n",
    "        wavelength_grid.extend(np.arange(start, end + step, step))\n",
    "    \n",
    "    return np.array(wavelength_grid)\n",
    "\n",
    "def normalize_wavelengths(wavelengths, max_wavelength):\n",
    "    return wavelengths / max_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd45f21-e0c2-4169-ae18-35ef916e9e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34714, 10])\n"
     ]
    }
   ],
   "source": [
    "# Generate wavelength grid\n",
    "wavelength_grid = generate_wavelength_grid()\n",
    "\n",
    "# Normalize the wavelength grid\n",
    "max_wavelength = 17100\n",
    "normalized_wavelength_grid = normalize_wavelengths(wavelength_grid, max_wavelength)\n",
    "\n",
    "# Initialize Positional Encoding with the arguments from config\n",
    "positional_encoding = PositionalEncoding(pe_args)\n",
    "\n",
    "# Generate positional encoding tensor\n",
    "wavelength_grid_tensor = torch.tensor(normalized_wavelength_grid, dtype=torch.float16)\n",
    "pe_tensor = positional_encoding(wavelength_grid_tensor)\n",
    "\n",
    "print(pe_tensor.shape)  # Verify the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411b00ea-0a4b-42a9-908c-8ed6389475bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4727,  0.9746, -0.3076,  ...,  0.9517,  0.8340, -0.6118],\n",
      "        [-0.4736,  0.9746, -0.3083,  ...,  0.9512,  0.8340, -0.6143],\n",
      "        [-0.4736,  0.9746, -0.3083,  ...,  0.9512,  0.8340, -0.6143],\n",
      "        ...,\n",
      "        [ 0.3794,  0.9937,  0.2966,  ...,  0.9551,  1.0000,  0.7573],\n",
      "        [ 0.3794,  0.9937,  0.2966,  ...,  0.9551,  1.0000,  0.7573],\n",
      "        [ 0.3794,  0.9937,  0.2966,  ...,  0.9551,  1.0000,  0.7573]],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(pe_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a101c714-1d82-4a22-9540-12979ac7a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15050.   15050.2  15050.4  ...  7919.95  7920.    7920.05]\n"
     ]
    }
   ],
   "source": [
    "print (wavelength_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60529ea-1882-46c8-ae2f-4a35833fde6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains NaNs: False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in the pe_tensor\n",
    "contains_nan = torch.isnan(pe_tensor).any()\n",
    "print(f\"Contains NaNs: {contains_nan}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a230d8-0c73-42a1-a2e6-15607f249a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import IterableSpectraDataset, collate_fn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6491eaf-3010-4205-bbae-e24c6681b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_dir = '../data/healpixfiles_inter'\n",
    "dataset = IterableSpectraDataset(hdf5_dir, n_samples_per_spectrum=1000, n_subspectra=5, yield_full_spectrum=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f13f92ca-72c0-4dfc-b71a-df66e33033da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelength shape: torch.Size([32, 25300])\n",
      "Flux shape: torch.Size([32, 25300])\n",
      "Spectrum IDs: ('63_apogee_121', '73_apogee_105', '73_apogee_270', '73_apogee_295', '20_apogee_104', '20_apogee_273', '20_apogee_274', '32_apogee_129', '32_apogee_214', '32_apogee_245', '185_galah_332', '185_galah_336', '185_galah_355', '185_galah_391', '182_apogee_102', '182_apogee_115', '182_apogee_145', '182_apogee_193', '182_apogee_197', '182_apogee_199', '182_apogee_202', '182_apogee_234', '182_apogee_239', '182_apogee_243', '182_apogee_250', '182_apogee_299', '182_galah_315', '182_galah_343', '182_galah_392', '59_apogee_114', '59_galah_324', '149_apogee_172')\n",
      "Lengths: tensor([ 9495,  9495,  9495,  9495,  9495,  9495,  9495,  9495,  9495,  9495,\n",
      "        20761, 20775, 20766, 20760,  9495,  9495,  9495,  9495,  9495,  9495,\n",
      "         9495,  9495,  9495,  9495,  9495,  9495, 20758, 20776, 20767,  9495,\n",
      "        20775,  9495])\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# Print shapes of wavelength and flux tensors, and the spectrum IDs\n",
    "print(\"Wavelength shape:\", first_batch['wavelength'].shape)\n",
    "print(\"Flux shape:\", first_batch['flux'].shape)\n",
    "print(\"Spectrum IDs:\", first_batch['spectrum_id'])\n",
    "print(\"Lengths:\", first_batch['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df12f2f3-e9ff-443b-94f6-e9ef0d4df448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Generator, DownsamplingLayer, FullNetwork\n",
    "from pe import PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46803d46-fddb-4935-bac8-76149386f9bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FullNetwork.__init__() missing 1 required positional argument: 'positional_encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m downsampling_layer \u001b[38;5;241m=\u001b[39m DownsamplingLayer()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create the full network\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m full_network \u001b[38;5;241m=\u001b[39m \u001b[43mFullNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownsampling_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Define Positional Encoding\u001b[39;00m\n\u001b[1;32m     17\u001b[0m pe_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Dimension of the input (wavelengths)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m128\u001b[39m,  \u001b[38;5;66;03m# pe_dim example value\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m42\u001b[39m  \u001b[38;5;66;03m# seed example value\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: FullNetwork.__init__() missing 1 required positional argument: 'positional_encoding'"
     ]
    }
   ],
   "source": [
    "# Example configuration\n",
    "latent_dim = 5  # Example latent dimension\n",
    "output_dim = 25300  # Example output dimension (max length of wavelengths)\n",
    "layers = [512, 512]  # Example hidden layers\n",
    "activation_function = 'LeakyReLU'  # Example activation function\n",
    "\n",
    "# Define Generator\n",
    "generator = Generator(latent_dim, output_dim, layers, activation_function)\n",
    "\n",
    "# Define downsampling layer\n",
    "downsampling_layer = DownsamplingLayer()\n",
    "\n",
    "# Create the full network\n",
    "full_network = FullNetwork(generator, downsampling_layer)\n",
    "\n",
    "# Define Positional Encoding\n",
    "pe_args = (\n",
    "    1,  # Dimension of the input (wavelengths)\n",
    "    128,  # pe_dim example value\n",
    "    1.0,  # omega example value\n",
    "    1.0,  # sigma example value\n",
    "    True,  # pe_bias example value\n",
    "    42  # seed example value\n",
    ")\n",
    "\n",
    "positional_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e86b7a-b0b6-48ca-9f9a-a692a14fae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = PositionalEncoding(pe_args)\n",
    "print(positional_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679b653-109a-4f52-9dd9-c2bc3ed7138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate positional encoding tensor\n",
    "wavelength_grid = torch.tensor(generate_wavelength_grid(), dtype=torch.float32)\n",
    "wavelength_grid = normalize_wavelengths(wavelength_grid, 17100)  # Normalize the wavelength grid\n",
    "\n",
    "# Example input tensors\n",
    "batch_size = 5\n",
    "latent_z = first_batch['latent_code']  # Example latent space vector\n",
    "observed_wavelength = torch.randn((batch_size, positional_dim))  # Example observed wavelengths\n",
    "\n",
    "# Use positional encoding by reference\n",
    "positional_encoding_ref = positional_encoding(wavelength_grid)\n",
    "\n",
    "# Forward pass\n",
    "generated_flux = full_network(latent_z, positional_encoding_ref, observed_wavelength)\n",
    "\n",
    "# Print the shape of the generated flux\n",
    "print(f\"Generated flux shape: {generated_flux.shape}\")\n",
    "\n",
    "# Define the weighted MSE loss function\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2) \n",
    "    return loss\n",
    "\n",
    "# Example target and weight tensors\n",
    "sampled_flux = first_batch['flux']  # Example sampled flux (real flux)\n",
    "weights = first_batch['weight']  # Example weights\n",
    "\n",
    "# Compute the weighted MSE loss\n",
    "loss = weighted_mse_loss(generated_flux, sampled_flux, weights)\n",
    "\n",
    "# Backpropagation\n",
    "optimizer = torch.optim.Adam(full_network.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print total loss\n",
    "print(f\"Total loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815fe2c-e54b-4d3b-888f-8166bee2c5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
