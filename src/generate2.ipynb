{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a051be8f-4516-4733-ab74-d29240f2120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from utils import get_config2, resolve_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Custom modules\n",
    "from dataset3 import APOGEEDataset\n",
    "from model2 import Generator\n",
    "from tqdm import tqdm\n",
    "from checkpoint import save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e94d295-a961-40df-8f95-14b6b77ef0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58082da4-4a4a-4b4c-8441-cdb55b59dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configurations():\n",
    "    config = get_config2()\n",
    "    \n",
    "    dataset_name = config['dataset_name']\n",
    "    dataset_config = config['datasets'][dataset_name]\n",
    "    data_path = resolve_path(dataset_config['path'])\n",
    "    checkpoints_path = resolve_path(config['paths']['checkpoints'])\n",
    "    latent_path = resolve_path(config['paths']['latent'])\n",
    "    plots_path = resolve_path(config['paths']['plots'])\n",
    "\n",
    "    batch_size = config['training']['batch_size']\n",
    "    num_workers = config['training']['num_workers']\n",
    "    num_epochs = config['training']['num_epochs']\n",
    "    learning_rate = config['training']['learning_rate']\n",
    "    latent_learning_rate = config['training']['latent_learning_rate']\n",
    "    latent_dim = config['training']['latent_dim']\n",
    "    checkpoint_interval = config['training']['checkpoint_interval']\n",
    "\n",
    "    return (config, data_path, checkpoints_path, latent_path, plots_path, \n",
    "            batch_size, num_workers, num_epochs, learning_rate, latent_learning_rate, latent_dim, checkpoint_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd67ed9-af1a-4fcb-8512-f4e76047554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing device ..\n",
      "Using device: cpu\n",
      "loading config..\n"
     ]
    }
   ],
   "source": [
    "print(\"initializing device ..\")\n",
    "device = initialize_device()\n",
    "print(\"loading config..\")\n",
    "(config, data_path, checkpoints_path, latent_path, plots_path,\n",
    " batch_size, num_workers, num_epochs, learning_rate, latent_learning_rate, latent_dim, checkpoint_interval) = load_configurations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13634fc-319b-4101-b7de-599f270b68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_real_vs_generated_batch(dataset, data_path, data_loader, generator, device, batch_index, plots_path):\n",
    "#     # Open the HDF5 file\n",
    "#     with h5py.File(data_path, 'r') as hdf5_file:\n",
    "\n",
    "#         # Find the specific batch\n",
    "#         batch = next((batch_data for i, batch_data in enumerate(data_loader) if i == batch_index), None)\n",
    "\n",
    "#         # Ensure the batch is found\n",
    "#         if batch is None:\n",
    "#             raise ValueError(f\"Batch index {batch_index} not found in the data loader.\")\n",
    "\n",
    "#         # Extract unique identifiers, real spectra, and masks from the batch\n",
    "#         unique_ids = batch['unique_id']\n",
    "#         real_spectra = batch['flux'].to(device)\n",
    "#         masks = batch['flux_mask'].to(device)\n",
    "\n",
    "#         # Generate the spectra using the generator model\n",
    "#         generator.eval()\n",
    "#         with torch.no_grad():\n",
    "#             latent_codes = [torch.tensor(hdf5_file[uid]['latent_code'][()]).to(device) for uid in unique_ids]\n",
    "#             latent_codes_tensor = torch.stack(latent_codes)\n",
    "#             generated_spectra = generator(latent_codes_tensor).cpu().numpy()\n",
    "\n",
    "#         # Plot real vs generated spectra for each item in the batch\n",
    "#         for i, uid in enumerate(unique_ids):\n",
    "#             real_spectrum = real_spectra[i].cpu().numpy()\n",
    "#             generated_spectrum = generated_spectra[i]\n",
    "#             mask = masks[i].cpu().numpy()\n",
    "\n",
    "#             # Calculate weighted MSE or another appropriate metric\n",
    "#             mse = np.mean((mask * (real_spectrum - generated_spectrum))**2) / np.mean(mask)\n",
    "\n",
    "#             plt.figure(figsize=(10, 5))\n",
    "#             plt.plot(real_spectrum, label='Real Spectrum', color='blue', alpha=0.7, linewidth=0.5)\n",
    "#             plt.plot(generated_spectrum, label='Generated Spectrum', color='red', alpha=0.7, linewidth=0.5)\n",
    "#             plt.title(f'Comparison of Real and Generated Spectra for {uid}\\nMasked MSE: {mse:.4f}')\n",
    "#             plt.xlabel('Wavelength Index')\n",
    "#             plt.ylabel('Flux')\n",
    "#             plt.legend()\n",
    "#             plt.grid(True)\n",
    "#             plt.savefig(os.path.join(plots_path, f'real_vs_generated_{uid}.png'))\n",
    "#             plt.show()\n",
    "#             plt.close()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359c3b28-4bca-4841-a361-854c27bda93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/arc/home/Amirabezine/deepSpectra/checkpoints/checkpoint_latest.pth.tar\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "# Initialize the dataset and data loader\n",
    "dataset = APOGEEDataset(data_path, max_files=50)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Initialize the generator model\n",
    "generator = Generator(config['training']['latent_dim'], config['model']['output_dim'], config['model']['generator_layers'], config['model']['activation_function']).to(device)\n",
    "\n",
    "# Load the latest checkpoint if available\n",
    "latest_checkpoint_path = os.path.join(checkpoints_path, 'checkpoint_latest.pth.tar')\n",
    "print(latest_checkpoint_path)\n",
    "if os.path.exists(latest_checkpoint_path):\n",
    "    checkpoint = torch.load(latest_checkpoint_path)\n",
    "    # print(checkpoint)\n",
    "    generator.load_state_dict(checkpoint['state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28bef1aa-bedc-4356-8d67-24f58b9cd5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # Plot the real vs generated spectra for the batch of index batc_index\n",
    "# batch_index = 0\n",
    "# plot_real_vs_generated_batch(dataset, data_path, data_loader, generator, device, batch_index, plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f75b5e-98ea-4d3c-910d-0c2f6f77c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_latent_evolution_through_epochs(hdf5_file_path, data_loader, device, plots_path):\n",
    "#     with h5py.File(hdf5_file_path, 'r') as hdf5_file:\n",
    "#         # Get the first batch from the data loader\n",
    "#         first_batch = next(iter(data_loader))\n",
    "#         unique_ids = first_batch['unique_id']\n",
    "\n",
    "#         # Prepare to collect latent codes for available epochs for each unique_id\n",
    "#         latents_over_epochs = {uid: [] for uid in unique_ids}\n",
    "#         epochs_available = {uid: [] for uid in unique_ids}\n",
    "\n",
    "#         # Loop over each unique_id to fetch available latent codes\n",
    "#         for uid in unique_ids:\n",
    "#             # Find all keys for the current unique_id that contain latent vectors\n",
    "#             keys = [key for key in hdf5_file[uid].keys() if key.startswith('latent_code_epoch_')]\n",
    "#             epochs = [int(key.split('_')[-1]) for key in keys]\n",
    "#             epochs.sort()\n",
    "#             epochs_available[uid] = epochs\n",
    "\n",
    "#             # Store the latent vectors for each available epoch\n",
    "#             for epoch in epochs:\n",
    "#                 latent_key = f\"{uid}/latent_code_epoch_{epoch}\"\n",
    "#                 latent_vector = torch.tensor(hdf5_file[latent_key][()], dtype=torch.float32, device=device)\n",
    "#                 latents_over_epochs[uid].append(latent_vector.cpu().numpy())\n",
    "\n",
    "#         # Plotting the evolution of latent vectors\n",
    "#         for uid, latents in latents_over_epochs.items():\n",
    "#             latents = np.array(latents)  # Convert list of arrays into a 2D numpy array\n",
    "#             epochs = epochs_available[uid]\n",
    "\n",
    "#             plt.figure(figsize=(12, 6))\n",
    "#             for i in range(latents.shape[1]):  # Assuming latents.shape[1] is the dimension of the latent vector\n",
    "#                 plt.plot(epochs, latents[:, i], marker='o', linestyle='-', label=f'Latent Dimension {i+1}')\n",
    "\n",
    "#             plt.title(f'Evolution of Latent Vectors for {uid} Across Epochs')\n",
    "#             plt.xlabel('Epoch')\n",
    "#             plt.ylabel('Latent Value')\n",
    "#             plt.xticks(epochs)  # Ensure that all epochs are labeled\n",
    "#             # plt.legend()\n",
    "#             plt.grid(True)\n",
    "#             plt.savefig(os.path.join(plots_path, f'latent_evolution_{uid}.png'))\n",
    "#             plt.show()\n",
    "#             plt.close()  # Close to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e347a78-66df-4060-a9ce-4503abb0afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_latent_evolution_through_epochs(data_path, data_loader, device, plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13bb536f-f041-442e-9b45-b4c74077d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def plot_real_vs_generated_batch(dataset, data_path, data_loader, generator, device, batch_index, plots_path):\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(data_path, 'r') as hdf5_file:\n",
    "        # Find the specific batch\n",
    "        batch = next((batch_data for i, batch_data in enumerate(data_loader) if i == batch_index), None)\n",
    "\n",
    "        # Ensure the batch is found\n",
    "        if batch is None:\n",
    "            raise ValueError(f\"Batch index {batch_index} not found in the data loader.\")\n",
    "\n",
    "        # Extract unique identifiers, real spectra, and masks from the batch\n",
    "        unique_ids = [uid.decode('utf-8') for uid in batch['unique_id']]  # Decode byte strings to normal strings\n",
    "        real_spectra = batch['flux'].to(device)\n",
    "        masks = batch['flux_mask'].to(device)\n",
    "\n",
    "        # Prepare to generate spectra using the latest available optimized latent codes\n",
    "        generator.eval()\n",
    "        generated_spectra = []\n",
    "        latent_codes = []\n",
    "\n",
    "        for uid in unique_ids:\n",
    "            # Attempt to fetch the latest optimized latent code\n",
    "            latent_path = f\"{uid}/optimized_latent_code/epoch_latest\"\n",
    "            if latent_path in hdf5_file[uid]:\n",
    "                latent_code = torch.tensor(hdf5_file[uid][latent_path][()]).to(device)\n",
    "                latent_codes.append(latent_code)\n",
    "            else:\n",
    "                # If no latest optimized latent code, use initial latent code or skip\n",
    "                print(f\"No optimized latent code for {uid}, using initial latent code.\")\n",
    "                if f\"{uid}/latent_code\" in hdf5_file[uid]:\n",
    "                    latent_code = torch.tensor(hdf5_file[uid]['latent_code'][()]).to(device)\n",
    "                    latent_codes.append(latent_code)\n",
    "                else:\n",
    "                    print(f\"No latent code available for {uid}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "        if latent_codes:\n",
    "            latent_codes_tensor = torch.stack(latent_codes)\n",
    "            with torch.no_grad():\n",
    "                generated_spectra = generator(latent_codes_tensor).cpu().numpy()\n",
    "\n",
    "            # Plot real vs generated spectra for each item where generation was possible\n",
    "            j = 0  # Index for generated spectra\n",
    "            for i, uid in enumerate(unique_ids):\n",
    "                if i >= len(latent_codes):\n",
    "                    continue  # Skip if no latent code was available\n",
    "\n",
    "                real_spectrum = real_spectra[i].cpu().numpy()\n",
    "                generated_spectrum = generated_spectra[j]\n",
    "                j += 1\n",
    "                mask = masks[i].cpu().numpy()\n",
    "\n",
    "                # Calculate weighted MSE or another appropriate metric\n",
    "                mse = np.mean((mask * (real_spectrum - generated_spectrum))**2) / np.mean(mask)\n",
    "\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.plot(real_spectrum, label='Real Spectrum', color='blue', alpha=0.7, linewidth=0.5)\n",
    "                plt.plot(generated_spectrum, label='Generated Spectrum', color='red', alpha=0.7, linewidth=0.5)\n",
    "                plt.title(f'Comparison of Real and Generated Spectra for {uid}\\nMasked MSE: {mse:.4f}')\n",
    "                plt.xlabel('Wavelength Index')\n",
    "                plt.ylabel('Flux')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.savefig(os.path.join(plots_path, f'real_vs_generated_{uid}.png'))\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb045a50-ed27-4b8d-8c83-c194084ec99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for apogee_dr17_100, skipping...\n",
      "No data available for apogee_dr17_1037, skipping...\n",
      "No data available for apogee_dr17_1016, skipping...\n",
      "No data available for apogee_dr17_1031, skipping...\n",
      "No data available for apogee_dr17_1021, skipping...\n",
      "No data available for apogee_dr17_1023, skipping...\n",
      "No data available for apogee_dr17_1033, skipping...\n",
      "No data available for apogee_dr17_1025, skipping...\n",
      "No data available for apogee_dr17_1041, skipping...\n",
      "No data available for apogee_dr17_1008, skipping...\n"
     ]
    }
   ],
   "source": [
    "plot_latent_evolution_through_epochs(data_path, data_loader, device, plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298e9c2-78e3-4db0-99c5-cd31fcd142d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
