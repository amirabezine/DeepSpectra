{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dc4f66-adf6-42f6-a3cc-8a3e82150cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pe import PositionalEncoding\n",
    "from model import Generator, DownsamplingLayer, FullNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dataset import IterableSpectraDataset, collate_fn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bb1731-c0aa-49ed-9e2f-6d52b46eebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: The expanded size of the tensor (20762) must match the existing size (20765) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20765] in group 184_galah_317\n",
      "Exception: The expanded size of the tensor (20762) must match the existing size (20778) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20778] in group 184_galah_322\n",
      "Exception: The expanded size of the tensor (20762) must match the existing size (20767) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20767] in group 191_galah_328\n",
      "Exception: The expanded size of the tensor (20762) must match the existing size (20764) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20764] in group 161_galah_344\n",
      "Exception: The expanded size of the tensor (20762) must match the existing size (20769) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20769] in group 161_galah_351\n",
      "Exception: The expanded size of the tensor (20762) must match the existing size (20765) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20765] in group 166_galah_310\n",
      "Exception: The expanded size of the tensor (20762) must match the existing size (20779) at non-singleton dimension 0.  Target sizes: [20762].  Tensor sizes: [20779] in group 87_galah_345\n",
      "Wavelength shape: torch.Size([10, 20762])\n",
      "Flux shape: torch.Size([10, 20762])\n",
      "Spectrum IDs: ('161_galah_325', '161_galah_387', '161_galah_395', '166_galah_389', '87_apogee_180', '69_apogee_216', '69_apogee_218', '168_galah_384', '73_apogee_105', '73_apogee_270')\n",
      "Lengths: tensor([20746, 20762, 20753, 20739,  9495,  9495,  9495, 20757,  9495,  9495])\n"
     ]
    }
   ],
   "source": [
    "hdf5_dir = '../data/healpixfiles_inter'\n",
    "dataset = IterableSpectraDataset(hdf5_dir, n_samples_per_spectrum=4000, n_subspectra=5, yield_full_spectrum=True)\n",
    "dataloader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "\n",
    "# Get the first batch\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# Print shapes of wavelength and flux tensors, and the spectrum IDs\n",
    "print(\"Wavelength shape:\", first_batch['wavelength'].shape)\n",
    "print(\"Flux shape:\", first_batch['flux'].shape)\n",
    "print(\"Spectrum IDs:\", first_batch['spectrum_id'])\n",
    "print(\"Lengths:\", first_batch['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391d5037-504d-4a6c-9611-aa3302f91050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavelength_grid():\n",
    "    grid = [\n",
    "        (15050, 15850, 0.2),\n",
    "        (15870, 16440, 0.2),\n",
    "        (16475, 17005, 0.2),\n",
    "        (4700, 4930, 0.05),\n",
    "        (5650, 5880, 0.05),\n",
    "        (6420, 6800, 0.05),\n",
    "        (7500, 7920, 0.05)\n",
    "    ]\n",
    "\n",
    "    wavelength_grid = []\n",
    "    for start, end, step in grid:\n",
    "        wavelength_grid.extend(np.arange(start, end + step, step))\n",
    "    \n",
    "    return np.array(wavelength_grid)\n",
    "\n",
    "def normalize_wavelengths(wavelengths, max_wavelength):\n",
    "    return wavelengths / max_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc836d04-4e7f-4ec8-a658-eb6ee9633203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wavelength grid (high resolution)\n",
    "wavelength_grid = torch.tensor(generate_wavelength_grid(), dtype=torch.float16)\n",
    "wavelength_grid = normalize_wavelengths(wavelength_grid, 17100)  # Normalize the wavelength grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e4d94-56de-4234-afb8-a28ff56bff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d061a6d6-ce8e-4588-8e35-deced3d043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration\n",
    "latent_dim = 20  # Example latent dimension\n",
    "output_dim = 20762  # Example output dimension (max length of wavelengths)\n",
    "layers = [512, 512]  # Example hidden layers\n",
    "activation_function = 'LeakyReLU'  # Example activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8104e2-2f3c-4f10-9f98-35a6fda88198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positional Encoding\n",
    "pe_args = (\n",
    "    1,  # Dimension of the input (wavelengths)\n",
    "    10,  # pe_dim example value\n",
    "    1.0,  # omega example value\n",
    "    1.0,  # sigma example value\n",
    "    True,  # pe_bias example value\n",
    "    42  # seed example value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afb6d99-d5c7-49b7-97c0-f5dd9a1dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = PositionalEncoding(pe_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e3507b-77c4-4a00-b823-17c05802c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator\n",
    "generator_output_dim= 1\n",
    "input_dim = latent_dim + pe_args[1]  # latent_dim + pe_dim\n",
    "generator = Generator(input_dim, generator_output_dim, layers, activation_function)\n",
    "\n",
    "# Define downsampling layer\n",
    "downsampling_layer = DownsamplingLayer()\n",
    "\n",
    "# Create the full network\n",
    "full_network = FullNetwork(generator, downsampling_layer, positional_encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fc5c78-aa1e-4bd0-b0b2-906684f730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input tensors\n",
    "batch_size = 10\n",
    "positional_dim = 25300  # Adjust according to your needs\n",
    "latent_z = first_batch['latent_code']  # Example latent space vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be672f37-09e3-4c1e-82c0-1ee6055f8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lower resolution real_wavelengths\n",
    "real_wavelengths = first_batch['wavelength']\n",
    "# real_wavelengths = real_wavelengths.unsqueeze(0).expand(batch_size, -1)  # Shape: [batch_size, 8000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155a47fe-3e7e-43af-b367-e99c19787446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_z shape: torch.Size([10, 20])\n",
      "wavelength_grid shape: torch.Size([34714])\n",
      "real_wavelengths shape: torch.Size([10, 20762])\n",
      "positional_encoding shape: torch.Size([10, 34714, 10])\n",
      "latent_z_expanded shape: torch.Size([10, 34714, 20])\n",
      "input_to_generator shape: torch.Size([10, 34714, 30])\n",
      "generator_output shape: torch.Size([10, 34714, 1])\n",
      "generator_output squeezed shape:  torch.Size([10, 34714])\n",
      "high_res_flux shape: torch.Size([10, 34714])\n",
      "high_res_flux shape: torch.Size([10, 34714])\n",
      "high_res_wavelength shape: torch.Size([34714])\n",
      "observed_wavelength shape: torch.Size([10, 20762])\n",
      "Reshaped high_res_flux shape: torch.Size([10, 1, 34714, 1])\n",
      "Grid shape: torch.Size([10, 1, 20762, 2])\n",
      "Sampled flux shape: torch.Size([10, 1, 1, 20762])\n",
      "generated_flux shape: torch.Size([10, 1, 20762])\n",
      "Generated flux shape: torch.Size([10, 1, 20762])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use positional encoding by reference\n",
    "positional_encoding_ref = positional_encoding(wavelength_grid)\n",
    "\n",
    "# Forward pass\n",
    "generated_flux = full_network(latent_z, wavelength_grid, real_wavelengths)\n",
    "\n",
    "# Print the shape of the generated flux\n",
    "print(f\"Generated flux shape: {generated_flux.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eccb520c-783c-4c10-a10a-f065b6cccb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weighted MSE loss function\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e743d86-094b-4b0d-bfb0-30a0c57da57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Shapes of input torch.Size([10, 20762]), target torch.Size([10, 20762]), and weight torch.Size([4, 20762]) must match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Compute the weighted MSE loss\u001b[39;00m\n\u001b[1;32m      6\u001b[0m generated_flux \u001b[38;5;241m=\u001b[39m generated_flux\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mweighted_mse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_flux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_flux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(full_network\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m, in \u001b[0;36mweighted_mse_loss\u001b[0;34m(input, target, weight)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweighted_mse_loss\u001b[39m(\u001b[38;5;28minput\u001b[39m, target, weight):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m target\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m weight\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShapes of input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, target \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must match\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(weight \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mAssertionError\u001b[0m: Shapes of input torch.Size([10, 20762]), target torch.Size([10, 20762]), and weight torch.Size([4, 20762]) must match"
     ]
    }
   ],
   "source": [
    "# Example target and weight tensors\n",
    "real_flux = first_batch['flux']  # Example real flux from dataset\n",
    "weights = torch.ones((batch_size, positional_dim))  # Example weights\n",
    "\n",
    "# Compute the weighted MSE loss\n",
    "generated_flux = generated_flux.squeeze(1)\n",
    "loss = weighted_mse_loss(generated_flux, real_flux, weights)\n",
    "\n",
    "# Backpropagation\n",
    "optimizer = torch.optim.Adam(full_network.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print total loss\n",
    "print(f\"Total loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11c821-a47c-489e-8afc-8e9e6ced2f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
