{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dc4f66-adf6-42f6-a3cc-8a3e82150cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pe import PositionalEncoding\n",
    "from model import Generator, DownsamplingLayer, FullNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391d5037-504d-4a6c-9611-aa3302f91050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavelength_grid():\n",
    "    grid = [\n",
    "        (15050, 15850, 0.2),\n",
    "        (15870, 16440, 0.2),\n",
    "        (16475, 17005, 0.2),\n",
    "        (4700, 4930, 0.05),\n",
    "        (5650, 5880, 0.05),\n",
    "        (6420, 6800, 0.05),\n",
    "        (7500, 7920, 0.05)\n",
    "    ]\n",
    "\n",
    "    wavelength_grid = []\n",
    "    for start, end, step in grid:\n",
    "        wavelength_grid.extend(np.arange(start, end + step, step))\n",
    "    \n",
    "    return np.array(wavelength_grid)\n",
    "\n",
    "def normalize_wavelengths(wavelengths, max_wavelength):\n",
    "    return wavelengths / max_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc836d04-4e7f-4ec8-a658-eb6ee9633203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wavelength grid (high resolution)\n",
    "wavelength_grid = torch.tensor(generate_wavelength_grid(), dtype=torch.float16)\n",
    "wavelength_grid = normalize_wavelengths(wavelength_grid, 17100)  # Normalize the wavelength grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d061a6d6-ce8e-4588-8e35-deced3d043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration\n",
    "latent_dim = 5  # Example latent dimension\n",
    "output_dim = 25300  # Example output dimension (max length of wavelengths)\n",
    "layers = [512, 512]  # Example hidden layers\n",
    "activation_function = 'LeakyReLU'  # Example activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8104e2-2f3c-4f10-9f98-35a6fda88198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positional Encoding\n",
    "pe_args = (\n",
    "    1,  # Dimension of the input (wavelengths)\n",
    "    10,  # pe_dim example value\n",
    "    1.0,  # omega example value\n",
    "    1.0,  # sigma example value\n",
    "    True,  # pe_bias example value\n",
    "    42  # seed example value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afb6d99-d5c7-49b7-97c0-f5dd9a1dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = PositionalEncoding(pe_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e3507b-77c4-4a00-b823-17c05802c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator\n",
    "input_dim = latent_dim + pe_args[1]  # latent_dim + pe_dim\n",
    "generator = Generator(input_dim, output_dim, layers, activation_function)\n",
    "\n",
    "# Define downsampling layer\n",
    "downsampling_layer = DownsamplingLayer()\n",
    "\n",
    "# Create the full network\n",
    "full_network = FullNetwork(generator, downsampling_layer, positional_encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fc5c78-aa1e-4bd0-b0b2-906684f730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input tensors\n",
    "batch_size = 5\n",
    "positional_dim = 25300  # Adjust according to your needs\n",
    "latent_z = torch.randn((batch_size, latent_dim))  # Example latent space vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be672f37-09e3-4c1e-82c0-1ee6055f8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lower resolution real_wavelengths\n",
    "real_wavelengths = torch.linspace(wavelength_grid.min(), wavelength_grid.max(), 8000)\n",
    "real_wavelengths = real_wavelengths.unsqueeze(0).expand(batch_size, -1)  # Shape: [batch_size, 8000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155a47fe-3e7e-43af-b367-e99c19787446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_z shape: torch.Size([5, 5])\n",
      "wavelength_grid shape: torch.Size([34714])\n",
      "real_wavelengths shape: torch.Size([5, 8000])\n",
      "positional_encoding shape: torch.Size([5, 34714, 10])\n",
      "latent_z_expanded shape: torch.Size([5, 34714, 5])\n",
      "input_to_generator shape: torch.Size([5, 34714, 15])\n",
      "high_res_flux shape: torch.Size([5, 878264200])\n",
      "high_res_flux shape: torch.Size([5, 878264200])\n",
      "high_res_wavelength shape: torch.Size([34714])\n",
      "observed_wavelength shape: torch.Size([5, 8000])\n",
      "Reshaped high_res_flux shape: torch.Size([5, 1, 878264200, 1])\n",
      "Grid shape: torch.Size([5, 1, 8000, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grid_sampler(): expected grid to have size 2 in last dimension, but got grid with sizes [5, 1, 8000, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m positional_encoding_ref \u001b[38;5;241m=\u001b[39m positional_encoding(wavelength_grid)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m generated_flux \u001b[38;5;241m=\u001b[39m \u001b[43mfull_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelength_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_wavelengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Print the shape of the generated flux\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated flux shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_flux\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/deepSpectra/src2/model.py:86\u001b[0m, in \u001b[0;36mFullNetwork.forward\u001b[0;34m(self, latent_z, wavelength_grid, real_wavelengths)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh_res_flux shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhigh_res_flux\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Interpolate to real wavelengths\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m generated_flux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsampling_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhigh_res_flux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelength_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_wavelengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_flux shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_flux\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_flux\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/deepSpectra/src2/model.py:48\u001b[0m, in \u001b[0;36mDownsamplingLayer.forward\u001b[0;34m(self, high_res_flux, high_res_wavelength, observed_wavelength)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrid shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Interpolate\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m sampled_flux \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhigh_res_flux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mborder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled flux shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampled_flux\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled_flux\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py:4351\u001b[0m, in \u001b[0;36mgrid_sample\u001b[0;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m   4343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   4344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malign_corners=True if the old behavior is desired. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the documentation of grid_sample for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4348\u001b[0m     )\n\u001b[1;32m   4349\u001b[0m     align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grid_sampler(): expected grid to have size 2 in last dimension, but got grid with sizes [5, 1, 8000, 1]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use positional encoding by reference\n",
    "positional_encoding_ref = positional_encoding(wavelength_grid)\n",
    "\n",
    "# Forward pass\n",
    "generated_flux = full_network(latent_z, wavelength_grid, real_wavelengths)\n",
    "\n",
    "# Print the shape of the generated flux\n",
    "print(f\"Generated flux shape: {generated_flux.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb520c-783c-4c10-a10a-f065b6cccb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weighted MSE loss function\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e743d86-094b-4b0d-bfb0-30a0c57da57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example target and weight tensors\n",
    "real_flux = torch.randn((batch_size, positional_dim))  # Example real flux from dataset\n",
    "weights = torch.ones((batch_size, positional_dim))  # Example weights\n",
    "\n",
    "# Compute the weighted MSE loss\n",
    "loss = weighted_mse_loss(generated_flux, real_flux, weights)\n",
    "\n",
    "# Backpropagation\n",
    "optimizer = torch.optim.Adam(full_network.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print total loss\n",
    "print(f\"Total loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11c821-a47c-489e-8afc-8e9e6ced2f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
