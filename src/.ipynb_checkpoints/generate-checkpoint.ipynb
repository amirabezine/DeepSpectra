{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834918c-5a04-4171-9c36-94c835a65113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53147f9-6783-4737-a2a8-0eef0e1f4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from utils import get_config2, resolve_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom modules\n",
    "from dataset2 import APOGEEDataset\n",
    "from model2 import Generator\n",
    "from tqdm import tqdm\n",
    "from checkpoint import save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71a51de-44cd-498d-8ad2-4866de79ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35657bb0-3229-42da-be29-c05946a8cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configurations():\n",
    "    config = get_config()\n",
    "    data_path = resolve_path(config['paths']['hdf5_data'])\n",
    "    checkpoints_path = resolve_path(config['paths']['checkpoints'])\n",
    "    latent_path = resolve_path(config['paths']['latent'])\n",
    "    plots_path = resolve_path(config['paths']['plots'])\n",
    "    tensorboard_path = resolve_path(config['paths']['tensorboard'])\n",
    "\n",
    "    batch_size = config['training']['batch_size']\n",
    "    num_workers = config['training']['num_workers']\n",
    "    num_epochs = config['training']['num_epochs']\n",
    "    learning_rate = config['training']['learning_rate']\n",
    "    latent_learning_rate = config['training']['latent_learning_rate']\n",
    "    latent_dim = config['training']['latent_dim']\n",
    "    checkpoint_interval = config['training']['checkpoint_interval']\n",
    "\n",
    "    return (config, data_path, checkpoints_path, latent_path, plots_path, tensorboard_path,\n",
    "            batch_size, num_workers, num_epochs, learning_rate, latent_learning_rate, latent_dim, checkpoint_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309efe9b-4fe2-4c8d-9a86-8bad6b2d24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58db5a79-2306-4f8b-b909-990e10b299bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_vs_generated_batch(checkpoints_path, latent_path, data_loader, generator, device, batch_index, plots_path):\n",
    "    # Load the latest latent codes\n",
    "    latent_files = sorted(os.listdir(latent_path))\n",
    "    last_latent_file = os.path.join(latent_path, latent_files[-1])\n",
    "    latents = np.load(last_latent_file, allow_pickle=True).item()\n",
    "    \n",
    "    # Find the specific batch\n",
    "    batch = None\n",
    "    for i, batch_data in enumerate(data_loader):\n",
    "        if i == batch_index:\n",
    "            batch = batch_data\n",
    "            break\n",
    "\n",
    "    # Ensure the batch is found\n",
    "    if batch is None:\n",
    "        raise ValueError(f\"Batch index {batch_index} not found in the data loader.\")\n",
    "    \n",
    "    # Extract the indexes and spectra from the batch\n",
    "    indices = batch['index']\n",
    "    real_spectra = batch['flux']\n",
    "    masks = batch['flux_mask']\n",
    "    \n",
    "    # Generate the spectra using the generator model\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        latent_codes = torch.tensor(latents['latent_codes'][indices]).to(device)\n",
    "        generated_spectra = generator(latent_codes).cpu().numpy()\n",
    "    \n",
    "    # Plot real vs generated spectra for each index in the batch\n",
    "    for i, index in enumerate(indices):\n",
    "        real_spectrum = real_spectra[i].cpu().numpy()\n",
    "        generated_spectrum = generated_spectra[i]\n",
    "        mask = masks[i].cpu()\n",
    "\n",
    "        mse = weighted_mse(torch.tensor(generated_spectrum), torch.tensor(real_spectrum), mask).item()\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(real_spectrum, label='Real Spectrum', color='blue', alpha=0.7, linewidth=0.5)\n",
    "        plt.plot(generated_spectrum, label='Generated Spectrum', color='red', alpha=0.7, linewidth=0.5)\n",
    "        plt.title(f'Comparison of Real and Generated Spectra for Spectrum Index {index}\\nMasked MSE: {mse:.4f}')\n",
    "        plt.ylim(0,1.2)\n",
    "        plt.xlabel('Wavelength Index')\n",
    "        plt.ylabel('Flux')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.savefig(os.path.join(plots_path, f'real_vs_generated_{index}.png'))\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd225af-9758-433c-8cc3-f4c1ddc9410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initializing device ..\")\n",
    "device = initialize_device()\n",
    "print(\"loading config..\")\n",
    "(config, data_path, checkpoints_path, latent_path, plots_path, tensorboard_path,\n",
    " batch_size, num_workers, num_epochs, learning_rate, latent_learning_rate, latent_dim, checkpoint_interval) = load_configurations()\n",
    "\n",
    "# Initialize the dataset and data loader\n",
    "dataset = APOGEEDataset(data_path, max_files=config['training']['max_files'])\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Initialize the generator model\n",
    "generator = Generator(config['training']['latent_dim'], config['model']['output_dim'], config['model']['generator_layers'], config['model']['activation_function']).to(device)\n",
    "\n",
    "# Load the latest checkpoint if available\n",
    "latest_checkpoint_path = os.path.join(checkpoints_path, 'checkpoint_latest.pth.tar')\n",
    "if os.path.exists(latest_checkpoint_path):\n",
    "    checkpoint = torch.load(latest_checkpoint_path)\n",
    "    generator.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Plot the real vs generated spectra for the batch of index batc_index\n",
    "batch_index = 10\n",
    "plot_real_vs_generated_batch(checkpoints_path, latent_path, train_loader, generator, device, batch_index, plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6b14ed-dfb2-48d9-86e3-8aff229742fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_evolution(latent_dir, spectrum_index, num_epochs, plots_path):\n",
    "    latent_evolution = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        latent_path = os.path.join(latent_dir, f'latent_codes_epoch_{epoch}.npy')\n",
    "        latent_data = np.load(latent_path, allow_pickle=True).item()\n",
    "        latent_codes = latent_data['latent_codes']\n",
    "        latent_evolution.append(latent_codes[spectrum_index])\n",
    "\n",
    "    latent_evolution = np.array(latent_evolution)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(latent_evolution.shape[1]):\n",
    "        plt.plot(latent_evolution[:, i], label=f'Latent Dimension {i + 1}')\n",
    "\n",
    "    plt.title(f'Evolution of Latent Space for Spectrum Index {spectrum_index}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Latent Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(plots_path, f'latent_evolution_{spectrum_index}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e54d5f9-dba4-4d7d-9a73-b22abe7d6709",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_latent_evolution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_latent_evolution\u001b[49m(latent_path, \u001b[38;5;241m355\u001b[39m, num_epochs, plots_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_latent_evolution' is not defined"
     ]
    }
   ],
   "source": [
    "plot_latent_evolution(latent_path, 355, num_epochs, plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177913c-673d-4a0d-a4fe-12fb8f37e4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
