{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dc4f66-adf6-42f6-a3cc-8a3e82150cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pe import PositionalEncoding\n",
    "from model import Generator, DownsamplingLayer, FullNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from utils import get_config2, resolve_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import csv\n",
    "import time\n",
    "import glob\n",
    "from dataset import IterableSpectraDataset, collate_fn\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488a40d9-7220-4c30-aac0-96c32e9a618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbcdfed-1c25-4a63-9487-c00ae633cb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = initialize_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29343a7-9df0-4e0e-bbe7-fea2fb800551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weighted MSE loss function\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29acdc8d-ea5b-4633-8f84-be478a2b438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configurations():\n",
    "    config = get_config2()\n",
    "    dataset_name = config['dataset_name']\n",
    "    dataset_config = config['datasets'][dataset_name]\n",
    "    data_path = resolve_path(dataset_config['path'])\n",
    "   \n",
    "    return (config, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21499520-fd1d-4277-9baa-3c9897864f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "(config, data_path) = load_configurations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ce38db9-4d36-4c4e-81bb-489b47d07335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(config, data_path):\n",
    "    n_samples_per_spectrum =  config['training']['n_samples_per_spectrum']\n",
    "    n_subspectra = config['training']['n_subspectra']\n",
    "    train_dataset = IterableSpectraDataset(data_path, is_validation=False,n_samples_per_spectrum=n_samples_per_spectrum, n_subspectra=n_subspectra)\n",
    "    val_dataset = IterableSpectraDataset(data_path, is_validation=True, n_samples_per_spectrum=n_samples_per_spectrum, n_subspectra=n_subspectra)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'], collate_fn=collate_fn, num_workers=config['training']['num_workers'], pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'], collate_fn=collate_fn, num_workers=config['training']['num_workers'], pin_memory=True)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fdb06bd-7707-4689-822d-d083b332c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = prepare_datasets(config, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c621363e-af7c-48e1-954c-8532f5c3590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelength shape: torch.Size([5, 25300])\n",
      "Flux shape: torch.Size([5, 25300])\n",
      "Spectrum IDs: ('43_apogee_215', '43_apogee_215', '43_apogee_253', '43_apogee_253', '43_apogee_296')\n",
      "Lengths: tensor([7000, 7000, 7000, 7000, 7000])\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch\n",
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "# Print shapes of wavelength and flux tensors, and the spectrum IDs\n",
    "print(\"Wavelength shape:\", first_batch['wavelength'].shape)\n",
    "print(\"Flux shape:\", first_batch['flux'].shape)\n",
    "print(\"Spectrum IDs:\", first_batch['spectrum_id'])\n",
    "print(\"Lengths:\", first_batch['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7799e69c-9a96-4df2-86e8-92affef6888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizers(config, generator, latent_codes):\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=config['training']['learning_rate'])\n",
    "    optimizer_l = optim.Adam([latent_codes], lr=config['training']['latent_learning_rate'])\n",
    "    return optimizer_g, optimizer_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "391d5037-504d-4a6c-9611-aa3302f91050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavelength_grid():\n",
    "    grid = [\n",
    "        (15050, 15850, 0.2),\n",
    "        (15870, 16440, 0.2),\n",
    "        (16475, 17005, 0.2),\n",
    "        (4700, 4930, 0.05),\n",
    "        (5650, 5880, 0.05),\n",
    "        (6420, 6800, 0.05),\n",
    "        (7500, 7920, 0.05)\n",
    "    ]\n",
    "\n",
    "    wavelength_grid = []\n",
    "    for start, end, step in grid:\n",
    "        wavelength_grid.extend(np.arange(start, end + step, step))\n",
    "    \n",
    "    return np.array(wavelength_grid)\n",
    "\n",
    "def normalize_wavelengths(wavelengths, max_wavelength):\n",
    "    return wavelengths / max_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc836d04-4e7f-4ec8-a658-eb6ee9633203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wavelength grid (high resolution)\n",
    "wavelength_grid = torch.tensor(generate_wavelength_grid(), dtype=torch.float16)\n",
    "wavelength_grid = normalize_wavelengths(wavelength_grid, 17100)  # Normalize the wavelength grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e4d94-56de-4234-afb8-a28ff56bff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d061a6d6-ce8e-4588-8e35-deced3d043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration\n",
    "latent_dim = config['training']['latent_dim']  # Example latent dimension\n",
    "output_dim = config['training']['n_samples_per_spectrum']  # Example output dimension (max length of wavelengths)\n",
    "layers = [512, 512]  # Example hidden layers\n",
    "activation_function = 'LeakyReLU'  # Example activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa8104e2-2f3c-4f10-9f98-35a6fda88198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positional Encoding\n",
    "pe_args = (\n",
    "    1,  # Dimension of the input (wavelengths)\n",
    "    10,  # pe_dim example value\n",
    "    1.0,  # omega example value\n",
    "    1.0,  # sigma example value\n",
    "    True,  # pe_bias example value\n",
    "    42  # seed example value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0afb6d99-d5c7-49b7-97c0-f5dd9a1dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = PositionalEncoding(pe_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99e3507b-77c4-4a00-b823-17c05802c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator\n",
    "generator_output_dim= 1\n",
    "input_dim = latent_dim + pe_args[1]  # latent_dim + pe_dim\n",
    "generator = Generator(input_dim, generator_output_dim, layers, activation_function)\n",
    "\n",
    "# Define downsampling layer\n",
    "downsampling_layer = DownsamplingLayer()\n",
    "\n",
    "# Create the full network\n",
    "full_network = FullNetwork(generator, downsampling_layer, positional_encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24fc5c78-aa1e-4bd0-b0b2-906684f730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input tensors\n",
    "batch_size = config['training']['batch_size']\n",
    "positional_dim = config['training']['n_samples_per_spectrum']  # Adjust according to your needs\n",
    "# latent_z = torch.randn((batch_size, latent_dim), device=device)  # Example latent space vector\n",
    "\n",
    "\n",
    "latent_codes = torch.randn(1, config['training']['latent_dim'], device=device)  # Initialize with a single random vector\n",
    "dict_latent_codes = {}\n",
    "\n",
    "\n",
    "## latent z is the batch['latent_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be672f37-09e3-4c1e-82c0-1ee6055f8a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 25300])\n"
     ]
    }
   ],
   "source": [
    "# Generate lower resolution real_wavelengths\n",
    "real_wavelengths = torch.linspace(wavelength_grid.min(), wavelength_grid.max(), 8000)\n",
    "real_wavelengths = real_wavelengths.unsqueeze(0).expand(batch_size, -1)  # Shape: [batch_size, 8000]\n",
    "\n",
    "\n",
    "real_wavelengths= first_batch['wavelength']\n",
    "print (real_wavelengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155a47fe-3e7e-43af-b367-e99c19787446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_z shape: torch.Size([4, 5])\n",
      "wavelength_grid shape: torch.Size([34714])\n",
      "real_wavelengths shape: torch.Size([4, 8000])\n",
      "positional_encoding shape: torch.Size([4, 34714, 10])\n",
      "latent_z_expanded shape: torch.Size([4, 34714, 5])\n",
      "input_to_generator shape: torch.Size([4, 34714, 15])\n",
      "generator_output shape: torch.Size([4, 34714, 1])\n",
      "generator_output squeezed shape:  torch.Size([4, 34714])\n",
      "high_res_flux shape: torch.Size([4, 34714])\n",
      "high_res_flux shape: torch.Size([4, 34714])\n",
      "high_res_wavelength shape: torch.Size([34714])\n",
      "observed_wavelength shape: torch.Size([4, 8000])\n",
      "Reshaped high_res_flux shape: torch.Size([4, 1, 34714, 1])\n",
      "Grid shape: torch.Size([4, 1, 8000, 2])\n",
      "Sampled flux shape: torch.Size([4, 1, 1, 8000])\n",
      "generated_flux shape: torch.Size([4, 1, 8000])\n",
      "Generated flux shape: torch.Size([4, 1, 8000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use positional encoding by reference\n",
    "positional_encoding_ref = positional_encoding(wavelength_grid)\n",
    "\n",
    "# Forward pass\n",
    "generated_flux = full_network(latent_z, wavelength_grid, real_wavelengths)\n",
    "\n",
    "# Print the shape of the generated flux\n",
    "print(f\"Generated flux shape: {generated_flux.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccb520c-783c-4c10-a10a-f065b6cccb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e743d86-094b-4b0d-bfb0-30a0c57da57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 1.0041241645812988\n"
     ]
    }
   ],
   "source": [
    "# Example target and weight tensors\n",
    "real_flux = torch.randn((batch_size, positional_dim))  # Example real flux from dataset\n",
    "weights = torch.ones((batch_size, positional_dim))  # Example weights\n",
    "\n",
    "# Compute the weighted MSE loss\n",
    "generated_flux = generated_flux.squeeze(1)\n",
    "loss = weighted_mse_loss(generated_flux, real_flux, weights)\n",
    "\n",
    "# Backpropagation\n",
    "optimizer = torch.optim.Adam(full_network.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print total loss\n",
    "print(f\"Total loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11c821-a47c-489e-8afc-8e9e6ced2f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
