{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dc4f66-adf6-42f6-a3cc-8a3e82150cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pe import PositionalEncoding\n",
    "from model import Generator, DownsamplingLayer, FullNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391d5037-504d-4a6c-9611-aa3302f91050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavelength_grid():\n",
    "    grid = [\n",
    "        (15050, 15850, 0.2),\n",
    "        (15870, 16440, 0.2),\n",
    "        (16475, 17005, 0.2),\n",
    "        (4700, 4930, 0.05),\n",
    "        (5650, 5880, 0.05),\n",
    "        (6420, 6800, 0.05),\n",
    "        (7500, 7920, 0.05)\n",
    "    ]\n",
    "\n",
    "    wavelength_grid = []\n",
    "    for start, end, step in grid:\n",
    "        wavelength_grid.extend(np.arange(start, end + step, step))\n",
    "    \n",
    "    return np.array(wavelength_grid)\n",
    "\n",
    "def normalize_wavelengths(wavelengths, max_wavelength):\n",
    "    return wavelengths / max_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc836d04-4e7f-4ec8-a658-eb6ee9633203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wavelength grid (high resolution)\n",
    "wavelength_grid = torch.tensor(generate_wavelength_grid(), dtype=torch.float16)\n",
    "wavelength_grid = normalize_wavelengths(wavelength_grid, 17100)  # Normalize the wavelength grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e4d94-56de-4234-afb8-a28ff56bff62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d061a6d6-ce8e-4588-8e35-deced3d043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration\n",
    "latent_dim = 5  # Example latent dimension\n",
    "output_dim = 8000  # Example output dimension (max length of wavelengths)\n",
    "layers = [512, 512]  # Example hidden layers\n",
    "activation_function = 'LeakyReLU'  # Example activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8104e2-2f3c-4f10-9f98-35a6fda88198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Positional Encoding\n",
    "pe_args = (\n",
    "    1,  # Dimension of the input (wavelengths)\n",
    "    10,  # pe_dim example value\n",
    "    1.0,  # omega example value\n",
    "    1.0,  # sigma example value\n",
    "    True,  # pe_bias example value\n",
    "    42  # seed example value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afb6d99-d5c7-49b7-97c0-f5dd9a1dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = PositionalEncoding(pe_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e3507b-77c4-4a00-b823-17c05802c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dim  generr =  1\n"
     ]
    }
   ],
   "source": [
    "# Define Generator\n",
    "generator_output_dim= 1\n",
    "input_dim = latent_dim + pe_args[1]  # latent_dim + pe_dim\n",
    "generator = Generator(input_dim, generator_output_dim, layers, activation_function)\n",
    "\n",
    "# Define downsampling layer\n",
    "downsampling_layer = DownsamplingLayer()\n",
    "\n",
    "# Create the full network\n",
    "full_network = FullNetwork(generator, downsampling_layer, positional_encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fc5c78-aa1e-4bd0-b0b2-906684f730b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input tensors\n",
    "batch_size = 4\n",
    "positional_dim = 8000  # Adjust according to your needs\n",
    "latent_z = torch.randn((batch_size, latent_dim))  # Example latent space vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be672f37-09e3-4c1e-82c0-1ee6055f8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lower resolution real_wavelengths\n",
    "real_wavelengths = torch.linspace(wavelength_grid.min(), wavelength_grid.max(), 8000)\n",
    "real_wavelengths = real_wavelengths.unsqueeze(0).expand(batch_size, -1)  # Shape: [batch_size, 8000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155a47fe-3e7e-43af-b367-e99c19787446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_z shape: torch.Size([4, 5])\n",
      "wavelength_grid shape: torch.Size([34714])\n",
      "real_wavelengths shape: torch.Size([4, 8000])\n",
      "positional_encoding shape: torch.Size([4, 34714, 10])\n",
      "latent_z_expanded shape: torch.Size([4, 34714, 5])\n",
      "input_to_generator shape: torch.Size([4, 34714, 15])\n",
      "generator_output shape: torch.Size([4, 34714, 1])\n",
      "generator_output squeezed shape:  torch.Size([4, 34714])\n",
      "high_res_flux shape: torch.Size([4, 34714])\n",
      "high_res_flux shape: torch.Size([4, 34714])\n",
      "high_res_wavelength shape: torch.Size([34714])\n",
      "observed_wavelength shape: torch.Size([4, 8000])\n",
      "Reshaped high_res_flux shape: torch.Size([4, 1, 34714, 1])\n",
      "Grid shape: torch.Size([4, 1, 8000, 2])\n",
      "Sampled flux shape: torch.Size([4, 1, 1, 8000])\n",
      "generated_flux shape: torch.Size([4, 1, 8000])\n",
      "Generated flux shape: torch.Size([4, 1, 8000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use positional encoding by reference\n",
    "positional_encoding_ref = positional_encoding(wavelength_grid)\n",
    "\n",
    "# Forward pass\n",
    "generated_flux = full_network(latent_z, wavelength_grid, real_wavelengths)\n",
    "\n",
    "# Print the shape of the generated flux\n",
    "print(f\"Generated flux shape: {generated_flux.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccb520c-783c-4c10-a10a-f065b6cccb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weighted MSE loss function\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e743d86-094b-4b0d-bfb0-30a0c57da57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 1.0041241645812988\n"
     ]
    }
   ],
   "source": [
    "# Example target and weight tensors\n",
    "real_flux = torch.randn((batch_size, positional_dim))  # Example real flux from dataset\n",
    "weights = torch.ones((batch_size, positional_dim))  # Example weights\n",
    "\n",
    "# Compute the weighted MSE loss\n",
    "generated_flux = generated_flux.squeeze(1)\n",
    "loss = weighted_mse_loss(generated_flux, real_flux, weights)\n",
    "\n",
    "# Backpropagation\n",
    "optimizer = torch.optim.Adam(full_network.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print total loss\n",
    "print(f\"Total loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11c821-a47c-489e-8afc-8e9e6ced2f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
