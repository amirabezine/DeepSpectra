{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a768d4b0-1b83-4a85-a32a-0214467214e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from utils import get_config, resolve_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Custom modules\n",
    "from dataset import APOGEEDataset\n",
    "from model2 import Generator\n",
    "from tqdm import tqdm\n",
    "from checkpoint import save_checkpoint, load_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4039c3-0016-4070-b07f-290ffdce78a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd58069-046e-4f10-b480-5aeb4c38183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(input, target, weight):\n",
    "    assert input.shape == target.shape == weight.shape, f'Shapes of input {input.shape}, target {target.shape}, and weight {weight.shape} must match'\n",
    "    loss = torch.mean(weight * (input - target) ** 2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6364447-7c40-4077-809c-2f26cce192f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "# Config paths and training params\n",
    "data_path = resolve_path(config['paths']['hdf5_data'])\n",
    "checkpoints_path = resolve_path(config['paths']['checkpoints'])\n",
    "latent_path = resolve_path(config['paths']['latent'])\n",
    "plots_path = resolve_path(config['paths']['plots'])\n",
    "tensorboard_path = resolve_path(config['paths']['tensorboard'])\n",
    "\n",
    "batch_size = config['training']['batch_size']\n",
    "num_workers = config['training']['num_workers']\n",
    "num_epochs = config['training']['num_epochs']\n",
    "learning_rate = config['training']['learning_rate']\n",
    "latent_learning_rate = config['training']['latent_learning_rate']\n",
    "latent_dim = config['training']['latent_dim']\n",
    "checkpoint_interval = config['training']['checkpoint_interval']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10bf7b42-00e0-4a6f-bb9f-582958449ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = APOGEEDataset(data_path, max_files=config['training']['max_files'])\n",
    "train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=config['training']['split_ratios'][1])\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'], shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'], shuffle=False, num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cc13bc-2868-46b4-9688-578b96506316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and latent codes\n",
    "generator = Generator(latent_dim, config['model']['output_dim'], config['model']['generator_layers'], config['model']['activation_function']).to('cuda')\n",
    "latent_codes = torch.randn(len(train_loader.dataset), latent_dim, requires_grad=True, device='cuda')\n",
    "\n",
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_l = optim.LBFGS([latent_codes], lr=latent_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cbda3d7-b315-41a7-a283-a24eef3a15e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at '/arc/home/Amirabezine/deepSpectra/checkpoints/checkpoint_latest.pth.tar'\n",
      "No checkpoint found at '/arc/home/Amirabezine/deepSpectra/checkpoints/checkpoint_best.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the checkpoint files\n",
    "latest_checkpoint_path = os.path.join(checkpoints_path, 'checkpoint_latest.pth.tar')\n",
    "best_checkpoint_path = os.path.join(checkpoints_path, 'checkpoint_best.pth.tar')\n",
    "\n",
    "# Attempt to load the latest checkpoint\n",
    "latest_checkpoint = load_checkpoint(latest_checkpoint_path)\n",
    "if latest_checkpoint:\n",
    "    try:\n",
    "        generator.load_state_dict(latest_checkpoint['generator_state'])\n",
    "        latent_codes.data = latest_checkpoint['latent_codes']\n",
    "        optimizer_g.load_state_dict(latest_checkpoint['optimizer_g_state'])\n",
    "        optimizer_l.load_state_dict(latest_checkpoint['optimizer_l_state'])\n",
    "        start_epoch = latest_checkpoint['epoch'] + 1  \n",
    "        print(\"Loaded latest checkpoint.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error loading state dictionaries from latest checkpoint: {e}\")\n",
    "else:\n",
    "    # Initialize everything for a fresh start if no latest checkpoint is found\n",
    "    generator.apply(Generator.init_weights)\n",
    "    latent_codes = torch.randn(len(train_loader.dataset), latent_dim, device=device, requires_grad=True)\n",
    "    optimizer_g = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "    optimizer_l = torch.optim.LBFGS([latent_codes], lr=latent_learning_rate)\n",
    "    start_epoch = 0\n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "scheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=config['training']['scheduler_step_size'], gamma=config['training']['scheduler_gamma'])\n",
    "scheduler_l = torch.optim.lr_scheduler.StepLR(optimizer_l, step_size=config['training']['scheduler_step_size'], gamma=config['training']['scheduler_gamma'])  # Assuming similar parameters\n",
    "\n",
    "# Attempt to load the best checkpoint\n",
    "best_checkpoint = load_checkpoint(best_checkpoint_path)\n",
    "if best_checkpoint:\n",
    "    try:\n",
    "        best_val_loss = best_checkpoint['best_val_loss']\n",
    "        print(f\"Best validation loss from checkpoint: {best_val_loss}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error retrieving best validation loss from checkpoint: {e}\")\n",
    "        best_val_loss = float('inf')\n",
    "else:\n",
    "    best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361d32f-1089-4694-880b-a594e3862e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/60:   0%|          | 0/41 [00:00<?, ?it/s]/opt/conda/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training Epoch 1/60: 100%|██████████| 41/41 [00:14<00:00,  2.24it/s, Batch Latent Loss=0.00342]/opt/conda/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training Epoch 1/60: 100%|██████████| 41/41 [00:15<00:00,  2.73it/s, Batch Latent Loss=0.00342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Train Loss: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/60: 100%|██████████| 10/10 [00:01<00:00,  8.17it/s, Batch Val Loss=0.00529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Validation Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/60: 100%|██████████| 41/41 [00:10<00:00,  3.98it/s, Batch Latent Loss=0.00386] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Train Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/60: 100%|██████████| 10/10 [00:01<00:00,  8.31it/s, Batch Val Loss=0.00192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Validation Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/60: 100%|██████████| 41/41 [00:03<00:00, 11.44it/s, Batch Latent Loss=0.00163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Train Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/60: 100%|██████████| 10/10 [00:01<00:00,  6.19it/s, Batch Val Loss=0.0019] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Validation Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/60: 100%|██████████| 41/41 [00:03<00:00, 11.36it/s, Batch Latent Loss=0.00296] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Train Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 4/60: 100%|██████████| 10/10 [00:01<00:00,  8.33it/s, Batch Val Loss=0.00237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Validation Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/60: 100%|██████████| 41/41 [00:04<00:00,  9.73it/s, Batch Latent Loss=0.00289] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Train Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5/60: 100%|██████████| 10/10 [00:01<00:00,  8.68it/s, Batch Val Loss=0.00241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Validation Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/60: 100%|██████████| 41/41 [00:03<00:00, 12.10it/s, Batch Latent Loss=0.00182] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Train Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 6/60: 100%|██████████| 10/10 [00:02<00:00,  4.44it/s, Batch Val Loss=0.00188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Validation Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/60: 100%|██████████| 41/41 [00:04<00:00,  9.52it/s, Batch Latent Loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Train Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 7/60: 100%|██████████| 10/10 [00:01<00:00,  7.95it/s, Batch Val Loss=0.00188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Validation Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/60: 100%|██████████| 41/41 [00:03<00:00, 11.84it/s, Batch Latent Loss=0.00678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Train Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 8/60: 100%|██████████| 10/10 [00:01<00:00,  7.69it/s, Batch Val Loss=0.00799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Validation Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/60: 100%|██████████| 41/41 [00:03<00:00, 12.13it/s, Batch Latent Loss=0.00605] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Train Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 9/60: 100%|██████████| 10/10 [00:01<00:00,  7.36it/s, Batch Val Loss=0.0104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Validation Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/60: 100%|██████████| 41/41 [00:03<00:00, 12.81it/s, Batch Latent Loss=0.00228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Train Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 10/60: 100%|██████████| 10/10 [00:01<00:00,  8.04it/s, Batch Val Loss=0.00296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Validation Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/60: 100%|██████████| 41/41 [00:03<00:00, 10.66it/s, Batch Latent Loss=0.00141] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 11/60: 100%|██████████| 10/10 [00:01<00:00,  8.33it/s, Batch Val Loss=0.0017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Validation Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/60: 100%|██████████| 41/41 [00:03<00:00, 12.48it/s, Batch Latent Loss=0.0014]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Train Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 12/60: 100%|██████████| 10/10 [00:01<00:00,  8.21it/s, Batch Val Loss=0.00157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/60: 100%|██████████| 41/41 [00:03<00:00, 11.62it/s, Batch Latent Loss=0.00103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 13/60: 100%|██████████| 10/10 [00:01<00:00,  8.13it/s, Batch Val Loss=0.00168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Validation Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/60: 100%|██████████| 41/41 [00:03<00:00, 10.32it/s, Batch Latent Loss=0.00145] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Train Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 14/60: 100%|██████████| 10/10 [00:01<00:00,  8.32it/s, Batch Val Loss=0.00396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Validation Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/60: 100%|██████████| 41/41 [00:03<00:00, 11.71it/s, Batch Latent Loss=0.000698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 15/60: 100%|██████████| 10/10 [00:01<00:00,  7.77it/s, Batch Val Loss=0.00158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/60: 100%|██████████| 41/41 [00:03<00:00, 12.95it/s, Batch Latent Loss=0.00884] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Train Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 16/60: 100%|██████████| 10/10 [00:01<00:00,  8.21it/s, Batch Val Loss=0.00176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Validation Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/60: 100%|██████████| 41/41 [00:03<00:00, 12.97it/s, Batch Latent Loss=0.00263] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Train Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 17/60: 100%|██████████| 10/10 [00:01<00:00,  8.25it/s, Batch Val Loss=0.00153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/60: 100%|██████████| 41/41 [00:03<00:00, 12.32it/s, Batch Latent Loss=0.00106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 18/60: 100%|██████████| 10/10 [00:01<00:00,  8.57it/s, Batch Val Loss=0.00175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/60: 100%|██████████| 41/41 [00:03<00:00, 11.54it/s, Batch Latent Loss=0.00225] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 19/60: 100%|██████████| 10/10 [00:01<00:00,  8.33it/s, Batch Val Loss=0.00155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/60: 100%|██████████| 41/41 [00:03<00:00, 12.86it/s, Batch Latent Loss=0.00279] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 20/60: 100%|██████████| 10/10 [00:01<00:00,  8.59it/s, Batch Val Loss=0.00166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/60: 100%|██████████| 41/41 [00:03<00:00, 11.69it/s, Batch Latent Loss=0.000628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 21/60: 100%|██████████| 10/10 [00:01<00:00,  7.25it/s, Batch Val Loss=0.00181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Validation Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/60: 100%|██████████| 41/41 [00:03<00:00, 12.38it/s, Batch Latent Loss=0.00285] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Train Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 22/60: 100%|██████████| 10/10 [00:01<00:00,  8.83it/s, Batch Val Loss=0.00261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Validation Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/60: 100%|██████████| 41/41 [00:03<00:00, 12.34it/s, Batch Latent Loss=0.00283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Train Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 23/60: 100%|██████████| 10/10 [00:01<00:00,  7.86it/s, Batch Val Loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Validation Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/60: 100%|██████████| 41/41 [00:04<00:00,  9.99it/s, Batch Latent Loss=0.0101]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Train Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 24/60: 100%|██████████| 10/10 [00:01<00:00,  6.78it/s, Batch Val Loss=0.00168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Validation Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/60: 100%|██████████| 41/41 [00:03<00:00, 10.88it/s, Batch Latent Loss=0.0108]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Train Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 25/60: 100%|██████████| 10/10 [00:01<00:00,  7.55it/s, Batch Val Loss=0.00193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Validation Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/60: 100%|██████████| 41/41 [00:04<00:00, 10.24it/s, Batch Latent Loss=0.0014]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Train Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 26/60: 100%|██████████| 10/10 [00:01<00:00,  8.30it/s, Batch Val Loss=0.00366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Validation Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/60: 100%|██████████| 41/41 [00:04<00:00, 10.08it/s, Batch Latent Loss=0.00312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Train Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 27/60: 100%|██████████| 10/10 [00:01<00:00,  6.00it/s, Batch Val Loss=0.00411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Validation Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/60: 100%|██████████| 41/41 [00:03<00:00, 10.96it/s, Batch Latent Loss=0.00102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Average Train Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 28/60: 100%|██████████| 10/10 [00:01<00:00,  8.60it/s, Batch Val Loss=0.00244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Average Validation Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/60: 100%|██████████| 41/41 [00:03<00:00, 12.54it/s, Batch Latent Loss=0.00117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Average Train Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 29/60: 100%|██████████| 10/10 [00:01<00:00,  8.28it/s, Batch Val Loss=0.00174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Average Validation Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/60: 100%|██████████| 41/41 [00:03<00:00, 12.17it/s, Batch Latent Loss=0.00124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Average Train Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 30/60: 100%|██████████| 10/10 [00:01<00:00,  8.15it/s, Batch Val Loss=0.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Average Validation Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/60: 100%|██████████| 41/41 [00:03<00:00, 11.39it/s, Batch Latent Loss=0.00214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Average Train Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 31/60: 100%|██████████| 10/10 [00:01<00:00,  7.06it/s, Batch Val Loss=0.00221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Average Validation Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/60: 100%|██████████| 41/41 [00:03<00:00, 10.25it/s, Batch Latent Loss=0.00402] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Average Train Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 32/60: 100%|██████████| 10/10 [00:01<00:00,  8.73it/s, Batch Val Loss=0.00527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Average Validation Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/60: 100%|██████████| 41/41 [00:03<00:00, 12.35it/s, Batch Latent Loss=0.00439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Average Train Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 33/60: 100%|██████████| 10/10 [00:01<00:00,  9.12it/s, Batch Val Loss=0.00293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Average Validation Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/60: 100%|██████████| 41/41 [00:03<00:00, 13.47it/s, Batch Latent Loss=0.00301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Average Train Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 34/60: 100%|██████████| 10/10 [00:01<00:00,  8.84it/s, Batch Val Loss=0.00426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Average Validation Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/60: 100%|██████████| 41/41 [00:03<00:00, 12.65it/s, Batch Latent Loss=0.0013] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Average Train Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 35/60: 100%|██████████| 10/10 [00:01<00:00,  8.49it/s, Batch Val Loss=0.00207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Average Validation Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/60: 100%|██████████| 41/41 [00:03<00:00, 10.90it/s, Batch Latent Loss=0.00103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 36/60: 100%|██████████| 10/10 [00:01<00:00,  8.63it/s, Batch Val Loss=0.00159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/60: 100%|██████████| 41/41 [00:03<00:00, 13.06it/s, Batch Latent Loss=0.000794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 37/60: 100%|██████████| 10/10 [00:01<00:00,  8.54it/s, Batch Val Loss=0.00146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Average Validation Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/60: 100%|██████████| 41/41 [00:03<00:00, 11.77it/s, Batch Latent Loss=0.000964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 38/60: 100%|██████████| 10/10 [00:01<00:00,  6.34it/s, Batch Val Loss=0.00155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/60: 100%|██████████| 41/41 [00:03<00:00, 13.25it/s, Batch Latent Loss=0.00173] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 39/60: 100%|██████████| 10/10 [00:01<00:00,  8.05it/s, Batch Val Loss=0.00155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/60: 100%|██████████| 41/41 [00:03<00:00, 11.37it/s, Batch Latent Loss=0.00197] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 40/60: 100%|██████████| 10/10 [00:01<00:00,  8.46it/s, Batch Val Loss=0.00185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Average Validation Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41/60: 100%|██████████| 41/41 [00:03<00:00, 10.97it/s, Batch Latent Loss=0.0015]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 41/60: 100%|██████████| 10/10 [00:01<00:00,  8.70it/s, Batch Val Loss=0.0016] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42/60: 100%|██████████| 41/41 [00:03<00:00, 11.85it/s, Batch Latent Loss=0.00194] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Average Train Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 42/60: 100%|██████████| 10/10 [00:01<00:00,  8.46it/s, Batch Val Loss=0.00186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Average Validation Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43/60: 100%|██████████| 41/41 [00:06<00:00,  6.25it/s, Batch Latent Loss=0.0043]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 43/60: 100%|██████████| 10/10 [00:01<00:00,  5.08it/s, Batch Val Loss=0.00164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Average Validation Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44/60: 100%|██████████| 41/41 [00:03<00:00, 11.98it/s, Batch Latent Loss=0.000488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 44/60: 100%|██████████| 10/10 [00:02<00:00,  4.86it/s, Batch Val Loss=0.00157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Average Validation Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45/60: 100%|██████████| 41/41 [00:03<00:00, 11.48it/s, Batch Latent Loss=0.00139] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 45/60: 100%|██████████| 10/10 [00:01<00:00,  7.19it/s, Batch Val Loss=0.00168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46/60: 100%|██████████| 41/41 [00:03<00:00, 12.66it/s, Batch Latent Loss=0.00171] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 46/60: 100%|██████████| 10/10 [00:01<00:00,  8.56it/s, Batch Val Loss=0.00156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47/60: 100%|██████████| 41/41 [00:04<00:00,  9.03it/s, Batch Latent Loss=0.00194] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 47/60: 100%|██████████| 10/10 [00:01<00:00,  8.80it/s, Batch Val Loss=0.00198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Average Validation Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48/60: 100%|██████████| 41/41 [00:03<00:00, 12.51it/s, Batch Latent Loss=0.000906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 48/60: 100%|██████████| 10/10 [00:01<00:00,  8.62it/s, Batch Val Loss=0.00177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49/60: 100%|██████████| 41/41 [00:03<00:00, 12.11it/s, Batch Latent Loss=0.00237] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 49/60: 100%|██████████| 10/10 [00:02<00:00,  4.22it/s, Batch Val Loss=0.00155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50/60: 100%|██████████| 41/41 [00:04<00:00,  9.61it/s, Batch Latent Loss=0.00414] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Average Train Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 50/60: 100%|██████████| 10/10 [00:01<00:00,  6.30it/s, Batch Val Loss=0.00145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51/60: 100%|██████████| 41/41 [00:03<00:00, 10.77it/s, Batch Latent Loss=0.000747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 51/60: 100%|██████████| 10/10 [00:01<00:00,  6.66it/s, Batch Val Loss=0.00161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52/60: 100%|██████████| 41/41 [00:03<00:00, 12.34it/s, Batch Latent Loss=0.00248] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 52/60: 100%|██████████| 10/10 [00:01<00:00,  9.31it/s, Batch Val Loss=0.00168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53/60: 100%|██████████| 41/41 [00:03<00:00, 13.57it/s, Batch Latent Loss=0.000927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 53/60: 100%|██████████| 10/10 [00:01<00:00,  8.94it/s, Batch Val Loss=0.0015] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Average Validation Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54/60: 100%|██████████| 41/41 [00:03<00:00, 12.93it/s, Batch Latent Loss=0.00121] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Average Train Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 54/60: 100%|██████████| 10/10 [00:01<00:00,  9.08it/s, Batch Val Loss=0.00164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55/60: 100%|██████████| 41/41 [00:03<00:00, 12.86it/s, Batch Latent Loss=0.0127]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Average Train Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 55/60: 100%|██████████| 10/10 [00:01<00:00,  9.17it/s, Batch Val Loss=0.00299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Average Validation Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56/60: 100%|██████████| 41/41 [00:03<00:00, 12.32it/s, Batch Latent Loss=0.00175] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Average Train Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 56/60: 100%|██████████| 10/10 [00:01<00:00,  7.58it/s, Batch Val Loss=0.00171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Average Validation Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57/60:  88%|████████▊ | 36/41 [00:03<00:00, 12.10it/s, Batch Latent Loss=0.00194] "
     ]
    }
   ],
   "source": [
    "# Initialize loss history storage\n",
    "loss_history = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    generator.train()\n",
    "    epoch_losses = []\n",
    "    train_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    for batch in train_bar:\n",
    "        indices = batch['index'].to(device)\n",
    "        flux = batch['flux'].to(device)\n",
    "        mask = batch['flux_mask'].to(device)\n",
    "        ivar = batch['sigma'].to(device)  # Assuming sigma is the inverse variance\n",
    "\n",
    "        # Step 1: Optimize generator weights\n",
    "        optimizer_g.zero_grad()\n",
    "        generated = generator(latent_codes[indices])\n",
    "        loss_g = weighted_mse_loss(generated, flux, mask)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        train_bar.set_postfix({\"Batch Weight Loss\": loss_g.item()})\n",
    "\n",
    "        # Step 2: Freeze generator weights and optimize latent codes\n",
    "        for param in generator.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        def closure():\n",
    "            optimizer_l.zero_grad()\n",
    "            generated = generator(latent_codes[indices])\n",
    "            \n",
    "            # # Apply mask, ASK SEB ABOUT THIS\n",
    "            # masked_generated = generated * mask\n",
    "            \n",
    "            loss_l = weighted_mse_loss(generated, flux, mask)\n",
    "            loss_l.backward()\n",
    "            epoch_losses.append(loss_l.item())\n",
    "            train_bar.set_postfix({\"Batch Latent Loss\": loss_l.item()})\n",
    "            return loss_l\n",
    "        \n",
    "        optimizer_l.step(closure)\n",
    "\n",
    "        # Unfreeze generator weights\n",
    "        for param in generator.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Calculate and store average loss for the epoch\n",
    "    average_train_loss = np.mean(epoch_losses)\n",
    "    loss_history['train'].append(average_train_loss)\n",
    "    print(f'Epoch {epoch+1} Average Train Loss: {average_train_loss:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    generator.eval()\n",
    "    val_losses = []\n",
    "    val_bar = tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}/{num_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            indices = batch['index'].to(device)\n",
    "            flux = batch['flux'].to(device)\n",
    "            mask = batch['flux_mask'].to(device)\n",
    "            \n",
    "            generated = generator(latent_codes[indices])\n",
    "            val_loss = weighted_mse_loss(generated, flux, mask)\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_bar.set_postfix({\"Batch Val Loss\": val_loss.item()})\n",
    "\n",
    "    average_val_loss = np.mean(val_losses)\n",
    "    loss_history['val'].append(average_val_loss)\n",
    "    print(f'Epoch {epoch+1} Average Validation Loss: {average_val_loss:.4f}')\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler_g.step()\n",
    "    scheduler_l.step()\n",
    "\n",
    "    # Checkpoint handling and latent codes saving\n",
    "    checkpoint_state = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': generator.state_dict(),\n",
    "        'latent_codes': latent_codes,\n",
    "        'optimizer_g_state': optimizer_g.state_dict(),\n",
    "        'optimizer_l_state': optimizer_l.state_dict(),\n",
    "        'train_loss': average_train_loss,\n",
    "        'val_loss': average_val_loss,\n",
    "        'best_loss': best_val_loss\n",
    "    }\n",
    "    save_checkpoint(checkpoint_state, filename=os.path.join(checkpoints_path, f'checkpoint_latest.pth.tar'))\n",
    "    if average_val_loss < best_val_loss:\n",
    "        best_val_loss = average_val_loss\n",
    "        save_checkpoint(checkpoint_state, filename=best_checkpoint_path)\n",
    "    save_checkpoint(checkpoint_state, filename=os.path.join(checkpoints_path, f'checkpoint_epoch_{epoch+1}.pth.tar'))\n",
    "\n",
    "    # Save all latent codes with their indices after every epoch\n",
    "    all_latent_data = {'latent_codes': latent_codes.detach().cpu().numpy(), 'indices': torch.arange(latent_codes.size(0)).numpy()}\n",
    "    np.save(os.path.join(latent_path, f'latent_codes_epoch_{epoch+1}.npy'), all_latent_data)\n",
    "\n",
    "# After training, save the loss history for later analysis or plotting\n",
    "np.save(os.path.join(checkpoints_path, 'loss_history.npy'), loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89965a-30cf-4ee5-9b96-fd1b307ff13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(loss_history_path):\n",
    "    # Load the loss history\n",
    "    loss_history = np.load(loss_history_path, allow_pickle=True).item()\n",
    "    \n",
    "    # Extract training and validation losses\n",
    "    train_losses = loss_history['train']\n",
    "    val_losses = loss_history['val']\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Losses Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(os.path.join(checkpoints_path, 'loss_history.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a92d4-d042-4660-90eb-e2ff20d6255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_evolution(latent_dir, spectrum_index, num_epochs):\n",
    "    latent_evolution = []\n",
    "    \n",
    "    # Load latent codes for each epoch and append the specific spectrum's latent code to the list\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        latent_path = os.path.join(latent_dir, f'latent_codes_epoch_{epoch}.npy')\n",
    "        latent_data = np.load(latent_path, allow_pickle=True).item()\n",
    "        latent_codes = latent_data['latent_codes']\n",
    "        latent_evolution.append(latent_codes[spectrum_index])\n",
    "\n",
    "    latent_evolution = np.array(latent_evolution)\n",
    "\n",
    "    # Plot each component of the latent code\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(latent_evolution.shape[1]):  # Assuming latent_codes have the same dimensionality across epochs\n",
    "        plt.plot(latent_evolution[:, i], label=f'Latent Dimension {i + 1}')\n",
    "    \n",
    "    plt.title(f'Evolution of Latent Space for Spectrum Index {spectrum_index}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Latent Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_evolution(latent_path, 0, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b8623-dc1c-456e-8363-f926401630ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_vs_generated(checkpoints_path, latent_path, data_loader, generator, device, spectrum_index):\n",
    "    \"\"\"\n",
    "    Plots the real versus generated spectrum for a given spectrum index.\n",
    "    \n",
    "    Args:\n",
    "    - checkpoints_path (str): Path to the directory containing model checkpoints.\n",
    "    - latent_path (str): Path to the directory containing saved latent codes.\n",
    "    - data_loader (DataLoader): DataLoader containing the dataset with real spectra.\n",
    "    - generator (torch.nn.Module): The generator model.\n",
    "    - device (torch.device): The device on which PyTorch operations should be performed.\n",
    "    - spectrum_index (int): The index of the spectrum to plot.\n",
    "    \"\"\"\n",
    "    # Load the last latent code\n",
    "    latent_files = sorted(os.listdir(latent_path))\n",
    "    last_latent_file = os.path.join(latent_path, latent_files[-1])\n",
    "    latents = np.load(last_latent_file, allow_pickle=True).item()\n",
    "    latent_code = torch.tensor(latents['latent_codes'][spectrum_index]).to(device)\n",
    "\n",
    "    # Generate the spectrum using the latent code\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_spectrum = generator(latent_code.unsqueeze(0)).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Load the real flux data\n",
    "    for batch in data_loader:\n",
    "        indices = batch['index']\n",
    "        if spectrum_index in indices:\n",
    "            real_spectrum = batch['flux'][indices == spectrum_index].squeeze(0).cpu().numpy()\n",
    "            break\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(real_spectrum, label='Real Spectrum', color='blue')\n",
    "    plt.plot(generated_spectrum, label='Generated Spectrum', color='red')\n",
    "    plt.title(f'Comparison of Real and Generated Spectra for Spectrum Index {spectrum_index}')\n",
    "    plt.xlabel('Wavelength Index')\n",
    "    plt.ylabel('Flux')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example of usage\n",
    "# Assuming you have 'generator', 'device' setup, and a 'data_loader' ready\n",
    "plot_real_vs_generated(checkpoints_path, latent_path, train_loader, generator, device, spectrum_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b6241-fbaa-4bc8-9b33-d1218d657d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
